{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "ed2bd3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "from sklearn import *\n",
    "from bs4 import BeautifulSoup\n",
    "from snowballstemmer import TurkishStemmer\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "7a92b2fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>çekmiyor tsk berbat güzel</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vodafone bana niye trip atıyorsun acaba öğrene...</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@manyetikhamsi @vodafonetr maalesef müşteri hi...</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@tenshiroi vodafone , çekmiyor diyorlar ama he...</td>\n",
       "      <td>pozitif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#türktelekom bodrumda yok lakin , #vodafone on...</td>\n",
       "      <td>pozitif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Tweets Sentiment\n",
       "0                          çekmiyor tsk berbat güzel   negatif\n",
       "1  vodafone bana niye trip atıyorsun acaba öğrene...   negatif\n",
       "2  @manyetikhamsi @vodafonetr maalesef müşteri hi...   negatif\n",
       "3  @tenshiroi vodafone , çekmiyor diyorlar ama he...   pozitif\n",
       "4  #türktelekom bodrumda yok lakin , #vodafone on...   pozitif"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading dataset\n",
    "tw_data = pd.read_csv(r\"C:\\Users\\Kofana\\Desktop\\data_analysis\\gsm-tweets.csv\", encoding=\"latin5\")\n",
    "tw_data.columns = [ 'Tweets', 'Sentiment']\n",
    "tw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "c2baffff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1729</td>\n",
       "      <td>1729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1716</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>allah belanı versin #türkcell bir daha seni te...</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2</td>\n",
       "      <td>1466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Tweets Sentiment\n",
       "count                                                1729      1729\n",
       "unique                                               1716         2\n",
       "top     allah belanı versin #türkcell bir daha seni te...   negatif\n",
       "freq                                                    2      1466"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#information about data\n",
    "tw_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "4f1135ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the \"NAN\" values from dataset\n",
    "tw_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "2ff3599a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1729</td>\n",
       "      <td>1729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1716</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>allah belanı versin #türkcell bir daha seni te...</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2</td>\n",
       "      <td>1466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Tweets Sentiment\n",
       "count                                                1729      1729\n",
       "unique                                               1716         2\n",
       "top     allah belanı versin #türkcell bir daha seni te...   negatif\n",
       "freq                                                    2      1466"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#information about data\n",
    "tw_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "064821ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>TextSizeBeforeRemoveStopWords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>çekmiyor tsk berbat güzel</td>\n",
       "      <td>negatif</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vodafone bana niye trip atıyorsun acaba öğrene...</td>\n",
       "      <td>negatif</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@manyetikhamsi @vodafonetr maalesef müşteri hi...</td>\n",
       "      <td>negatif</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@tenshiroi vodafone , çekmiyor diyorlar ama he...</td>\n",
       "      <td>pozitif</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#türktelekom bodrumda yok lakin , #vodafone on...</td>\n",
       "      <td>pozitif</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Tweets Sentiment  \\\n",
       "0                          çekmiyor tsk berbat güzel   negatif   \n",
       "1  vodafone bana niye trip atıyorsun acaba öğrene...   negatif   \n",
       "2  @manyetikhamsi @vodafonetr maalesef müşteri hi...   negatif   \n",
       "3  @tenshiroi vodafone , çekmiyor diyorlar ama he...   pozitif   \n",
       "4  #türktelekom bodrumda yok lakin , #vodafone on...   pozitif   \n",
       "\n",
       "   TextSizeBeforeRemoveStopWords  \n",
       "0                             25  \n",
       "1                            288  \n",
       "2                            187  \n",
       "3                            106  \n",
       "4                            165  "
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw_data['TextSizeBeforeRemoveStopWords'] = [len(t) for t in tw_data.Tweets]\n",
    "tw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "ae6f0c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalization methods\n",
    "from unicode_tr import unicode_tr  #https://github.com/emre/unicode_tr\n",
    "def convertLowerCase(text):\n",
    "    return unicode_tr(text)\n",
    "\n",
    "#remove username\n",
    "def remove_username(text):\n",
    "    return re.sub('@[^\\s]+','',text)\n",
    "\n",
    "#remove hashtags\n",
    "def remove_hashtags(text):\n",
    "    return re.sub('#[^\\s]+','',text)\n",
    "\n",
    "#remove punctuation\n",
    "def remove_punctuation(text):\n",
    "    # define punctuation\n",
    "    punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "    no_punct = ''\n",
    "    for char in text:\n",
    "        if char not in punctuations:\n",
    "            no_punct = no_punct + char\n",
    "    return no_punct\n",
    "\n",
    "def remove_numericChars(text):\n",
    "    result = ''.join([i for i in text if not i.isdigit()])\n",
    "    return result\n",
    "\n",
    "#remove the html\n",
    "def strip_html(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "1a76f6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove the noisy text\n",
    "def denoise_text(text):\n",
    " \n",
    "    text = convertLowerCase(text)\n",
    "    text = remove_username(text)\n",
    "    text = remove_hashtags(text)\n",
    "    text = remove_punctuation(text)\n",
    "    text = remove_numericChars(text)\n",
    "   \n",
    "   # text = strip_html(text)\n",
    "    return text\n",
    "\n",
    "tw_data['AfterPreProcessing'] = tw_data['Tweets'].apply(denoise_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "3a895aa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>TextSizeBeforeRemoveStopWords</th>\n",
       "      <th>AfterPreProcessing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>çekmiyor tsk berbat güzel</td>\n",
       "      <td>negatif</td>\n",
       "      <td>25</td>\n",
       "      <td>çekmiyor tsk berbat güzel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vodafone bana niye trip atıyorsun acaba öğrene...</td>\n",
       "      <td>negatif</td>\n",
       "      <td>288</td>\n",
       "      <td>vodafone bana niye trip atıyorsun acaba öğrene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@manyetikhamsi @vodafonetr maalesef müşteri hi...</td>\n",
       "      <td>negatif</td>\n",
       "      <td>187</td>\n",
       "      <td>maalesef müşteri hizmetlerine ulaşamazsınız ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@tenshiroi vodafone , çekmiyor diyorlar ama he...</td>\n",
       "      <td>pozitif</td>\n",
       "      <td>106</td>\n",
       "      <td>vodafone  çekmiyor diyorlar ama hem paketleri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#türktelekom bodrumda yok lakin , #vodafone on...</td>\n",
       "      <td>pozitif</td>\n",
       "      <td>165</td>\n",
       "      <td>bodrumda yok lakin   onun bana hediye ettiği ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Tweets Sentiment  \\\n",
       "0                          çekmiyor tsk berbat güzel   negatif   \n",
       "1  vodafone bana niye trip atıyorsun acaba öğrene...   negatif   \n",
       "2  @manyetikhamsi @vodafonetr maalesef müşteri hi...   negatif   \n",
       "3  @tenshiroi vodafone , çekmiyor diyorlar ama he...   pozitif   \n",
       "4  #türktelekom bodrumda yok lakin , #vodafone on...   pozitif   \n",
       "\n",
       "   TextSizeBeforeRemoveStopWords  \\\n",
       "0                             25   \n",
       "1                            288   \n",
       "2                            187   \n",
       "3                            106   \n",
       "4                            165   \n",
       "\n",
       "                                  AfterPreProcessing  \n",
       "0                          çekmiyor tsk berbat güzel  \n",
       "1  vodafone bana niye trip atıyorsun acaba öğrene...  \n",
       "2    maalesef müşteri hizmetlerine ulaşamazsınız ...  \n",
       "3   vodafone  çekmiyor diyorlar ama hem paketleri...  \n",
       "4   bodrumda yok lakin   onun bana hediye ettiği ...  "
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "597d46fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stopwords\n",
    "\n",
    "from trtokenizer.tr_tokenizer import SentenceTokenizer, WordTokenizer\n",
    "tokenizer = WordTokenizer()\n",
    "\n",
    "#Setting Turkish stopwords\n",
    "stopword_list = open(r\"C:\\Users\\Kofana\\Desktop\\data_analysis\\stop_words_turkish.txt\",  encoding = 'latin5').read().split()\n",
    "\n",
    "stop = set(stopword_list)\n",
    "\n",
    "def remove_stopwords(text, is_lower_case = True):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    if is_lower_case:\n",
    "        filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "    else:\n",
    "        filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
    "    filtered_text = ' '.join(filtered_tokens)    \n",
    "    return filtered_text\n",
    "\n",
    "tw_data['AfterPreProcessing'] = tw_data['AfterPreProcessing'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "b4b8d4d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>TextSizeBeforeRemoveStopWords</th>\n",
       "      <th>AfterPreProcessing</th>\n",
       "      <th>TextSizeAfterRemoveStopWords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>çekmiyor tsk berbat güzel</td>\n",
       "      <td>negatif</td>\n",
       "      <td>25</td>\n",
       "      <td>çekmiyor tsk berbat güzel</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vodafone bana niye trip atıyorsun acaba öğrene...</td>\n",
       "      <td>negatif</td>\n",
       "      <td>288</td>\n",
       "      <td>vodafone trip atıyorsun öğrenebilir miyim tıkı...</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@manyetikhamsi @vodafonetr maalesef müşteri hi...</td>\n",
       "      <td>negatif</td>\n",
       "      <td>187</td>\n",
       "      <td>maalesef müşteri hizmetlerine ulaşamazsınız ul...</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@tenshiroi vodafone , çekmiyor diyorlar ama he...</td>\n",
       "      <td>pozitif</td>\n",
       "      <td>106</td>\n",
       "      <td>vodafone çekmiyor diyorlar paketleri fiyatları...</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#türktelekom bodrumda yok lakin , #vodafone on...</td>\n",
       "      <td>pozitif</td>\n",
       "      <td>165</td>\n",
       "      <td>bodrumda yok lakin hediye ettiği gb sayesinde ...</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Tweets Sentiment  \\\n",
       "0                          çekmiyor tsk berbat güzel   negatif   \n",
       "1  vodafone bana niye trip atıyorsun acaba öğrene...   negatif   \n",
       "2  @manyetikhamsi @vodafonetr maalesef müşteri hi...   negatif   \n",
       "3  @tenshiroi vodafone , çekmiyor diyorlar ama he...   pozitif   \n",
       "4  #türktelekom bodrumda yok lakin , #vodafone on...   pozitif   \n",
       "\n",
       "   TextSizeBeforeRemoveStopWords  \\\n",
       "0                             25   \n",
       "1                            288   \n",
       "2                            187   \n",
       "3                            106   \n",
       "4                            165   \n",
       "\n",
       "                                  AfterPreProcessing  \\\n",
       "0                          çekmiyor tsk berbat güzel   \n",
       "1  vodafone trip atıyorsun öğrenebilir miyim tıkı...   \n",
       "2  maalesef müşteri hizmetlerine ulaşamazsınız ul...   \n",
       "3  vodafone çekmiyor diyorlar paketleri fiyatları...   \n",
       "4  bodrumda yok lakin hediye ettiği gb sayesinde ...   \n",
       "\n",
       "   TextSizeAfterRemoveStopWords  \n",
       "0                            25  \n",
       "1                           288  \n",
       "2                           187  \n",
       "3                           106  \n",
       "4                           165  "
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw_data['TextSizeAfterRemoveStopWords'] = [len(t) for t in tw_data.Tweets]\n",
    "tw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "17551de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stemming\n",
    "turkStem = TurkishStemmer()\n",
    "\n",
    "# Stemming\n",
    "def simple_stemmer(text):\n",
    "    ss = TurkishStemmer()\n",
    "    text = ' '.join([ss.stemWord(word) for word in text.split()])\n",
    "    return text\n",
    "\n",
    "tw_data['AfterPreProcessing'] = tw_data['AfterPreProcessing'].apply(simple_stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "44719d55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>TextSizeBeforeRemoveStopWords</th>\n",
       "      <th>AfterPreProcessing</th>\n",
       "      <th>TextSizeAfterRemoveStopWords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>çekmiyor tsk berbat güzel</td>\n",
       "      <td>negatif</td>\n",
       "      <td>25</td>\n",
       "      <td>çekmiyor tsk berbat güzel</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vodafone bana niye trip atıyorsun acaba öğrene...</td>\n",
       "      <td>negatif</td>\n",
       "      <td>288</td>\n",
       "      <td>vodafone trip atıyor öğrenebilir mi tıkır tıkı...</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@manyetikhamsi @vodafonetr maalesef müşteri hi...</td>\n",
       "      <td>negatif</td>\n",
       "      <td>187</td>\n",
       "      <td>maalesef müşter hizmet ulaşamaz ulaşma sor çöz...</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@tenshiroi vodafone , çekmiyor diyorlar ama he...</td>\n",
       "      <td>pozitif</td>\n",
       "      <td>106</td>\n",
       "      <td>vodafone çekmiyor diyor paket fiyat mükemmel g...</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#türktelekom bodrumda yok lakin , #vodafone on...</td>\n",
       "      <td>pozitif</td>\n",
       "      <td>165</td>\n",
       "      <td>bodr yok lak hedi ettik gb saye çekirdek aile ...</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Tweets Sentiment  \\\n",
       "0                          çekmiyor tsk berbat güzel   negatif   \n",
       "1  vodafone bana niye trip atıyorsun acaba öğrene...   negatif   \n",
       "2  @manyetikhamsi @vodafonetr maalesef müşteri hi...   negatif   \n",
       "3  @tenshiroi vodafone , çekmiyor diyorlar ama he...   pozitif   \n",
       "4  #türktelekom bodrumda yok lakin , #vodafone on...   pozitif   \n",
       "\n",
       "   TextSizeBeforeRemoveStopWords  \\\n",
       "0                             25   \n",
       "1                            288   \n",
       "2                            187   \n",
       "3                            106   \n",
       "4                            165   \n",
       "\n",
       "                                  AfterPreProcessing  \\\n",
       "0                          çekmiyor tsk berbat güzel   \n",
       "1  vodafone trip atıyor öğrenebilir mi tıkır tıkı...   \n",
       "2  maalesef müşter hizmet ulaşamaz ulaşma sor çöz...   \n",
       "3  vodafone çekmiyor diyor paket fiyat mükemmel g...   \n",
       "4  bodr yok lak hedi ettik gb saye çekirdek aile ...   \n",
       "\n",
       "   TextSizeAfterRemoveStopWords  \n",
       "0                            25  \n",
       "1                           288  \n",
       "2                           187  \n",
       "3                           106  \n",
       "4                           165  "
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "94aecc42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>AfterPreProcessing</th>\n",
       "      <th>TextSizeAfterRemoveStopWords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>çekmiyor tsk berbat güzel</td>\n",
       "      <td>negatif</td>\n",
       "      <td>çekmiyor tsk berbat güzel</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vodafone bana niye trip atıyorsun acaba öğrene...</td>\n",
       "      <td>negatif</td>\n",
       "      <td>vodafone trip atıyor öğrenebilir mi tıkır tıkı...</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@manyetikhamsi @vodafonetr maalesef müşteri hi...</td>\n",
       "      <td>negatif</td>\n",
       "      <td>maalesef müşter hizmet ulaşamaz ulaşma sor çöz...</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@tenshiroi vodafone , çekmiyor diyorlar ama he...</td>\n",
       "      <td>pozitif</td>\n",
       "      <td>vodafone çekmiyor diyor paket fiyat mükemmel g...</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#türktelekom bodrumda yok lakin , #vodafone on...</td>\n",
       "      <td>pozitif</td>\n",
       "      <td>bodr yok lak hedi ettik gb saye çekirdek aile ...</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Tweets Sentiment  \\\n",
       "0                          çekmiyor tsk berbat güzel   negatif   \n",
       "1  vodafone bana niye trip atıyorsun acaba öğrene...   negatif   \n",
       "2  @manyetikhamsi @vodafonetr maalesef müşteri hi...   negatif   \n",
       "3  @tenshiroi vodafone , çekmiyor diyorlar ama he...   pozitif   \n",
       "4  #türktelekom bodrumda yok lakin , #vodafone on...   pozitif   \n",
       "\n",
       "                                  AfterPreProcessing  \\\n",
       "0                          çekmiyor tsk berbat güzel   \n",
       "1  vodafone trip atıyor öğrenebilir mi tıkır tıkı...   \n",
       "2  maalesef müşter hizmet ulaşamaz ulaşma sor çöz...   \n",
       "3  vodafone çekmiyor diyor paket fiyat mükemmel g...   \n",
       "4  bodr yok lak hedi ettik gb saye çekirdek aile ...   \n",
       "\n",
       "   TextSizeAfterRemoveStopWords  \n",
       "0                            25  \n",
       "1                           288  \n",
       "2                           187  \n",
       "3                           106  \n",
       "4                           165  "
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop unnecessary columnd\n",
    "tw_data = tw_data.drop(['TextSizeBeforeRemoveStopWords'], axis=1)\n",
    "tw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "2faa27bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>AfterPreProcessing</th>\n",
       "      <th>TextSizeAfterRemoveStopWords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>çekmiyor tsk berbat güzel</td>\n",
       "      <td>0</td>\n",
       "      <td>çekmiyor tsk berbat güzel</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vodafone bana niye trip atıyorsun acaba öğrene...</td>\n",
       "      <td>0</td>\n",
       "      <td>vodafone trip atıyor öğrenebilir mi tıkır tıkı...</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@manyetikhamsi @vodafonetr maalesef müşteri hi...</td>\n",
       "      <td>0</td>\n",
       "      <td>maalesef müşter hizmet ulaşamaz ulaşma sor çöz...</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@tenshiroi vodafone , çekmiyor diyorlar ama he...</td>\n",
       "      <td>1</td>\n",
       "      <td>vodafone çekmiyor diyor paket fiyat mükemmel g...</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#türktelekom bodrumda yok lakin , #vodafone on...</td>\n",
       "      <td>1</td>\n",
       "      <td>bodr yok lak hedi ettik gb saye çekirdek aile ...</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Tweets  Sentiment  \\\n",
       "0                          çekmiyor tsk berbat güzel          0   \n",
       "1  vodafone bana niye trip atıyorsun acaba öğrene...          0   \n",
       "2  @manyetikhamsi @vodafonetr maalesef müşteri hi...          0   \n",
       "3  @tenshiroi vodafone , çekmiyor diyorlar ama he...          1   \n",
       "4  #türktelekom bodrumda yok lakin , #vodafone on...          1   \n",
       "\n",
       "                                  AfterPreProcessing  \\\n",
       "0                          çekmiyor tsk berbat güzel   \n",
       "1  vodafone trip atıyor öğrenebilir mi tıkır tıkı...   \n",
       "2  maalesef müşter hizmet ulaşamaz ulaşma sor çöz...   \n",
       "3  vodafone çekmiyor diyor paket fiyat mükemmel g...   \n",
       "4  bodr yok lak hedi ettik gb saye çekirdek aile ...   \n",
       "\n",
       "   TextSizeAfterRemoveStopWords  \n",
       "0                            25  \n",
       "1                           288  \n",
       "2                           187  \n",
       "3                           106  \n",
       "4                           165  "
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#feature extraction\n",
    "tw_data.Sentiment.replace(['negatif', 'pozitif'], [0, 1], inplace = True)\n",
    "tw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "a80886d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset into train and test\n",
    "sent = tw_data['Sentiment']\n",
    "tw = tw_data['AfterPreProcessing']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(tw, sent, test_size = 0.20, random_state= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "5a8b4166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW_CV_Train: (1383, 23843)\n",
      "BoW_CV_Test: (346, 23843)\n"
     ]
    }
   ],
   "source": [
    "# CountVectorizer for Bag of Words\n",
    "cv = CountVectorizer(min_df = 0, max_df = 1, binary = False, ngram_range = (1, 3))\n",
    "\n",
    "# Transformed train tweets\n",
    "cv_train_tweets = cv.fit_transform(X_train)\n",
    "\n",
    "# Transformed test tweets\n",
    "cv_test_tweets = cv.transform(X_test)\n",
    "\n",
    "print('BoW_CV_Train:',cv_train_tweets.shape)\n",
    "print('BoW_CV_Test:',cv_test_tweets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "e5e607a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 10740)\t1\n",
      "  (0, 14387)\t1\n",
      "  (0, 8670)\t1\n",
      "  (0, 17411)\t1\n",
      "  (0, 2474)\t1\n",
      "  (0, 19926)\t1\n",
      "  (0, 22607)\t1\n",
      "  (0, 10741)\t1\n",
      "  (0, 14388)\t1\n",
      "  (0, 10739)\t1\n",
      "  (0, 8671)\t1\n"
     ]
    }
   ],
   "source": [
    "s = cv_train_tweets[1]\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "207c6d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ss = cv_test_tweets[1]\n",
    "print(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "6ff15c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tfidf_Train: (1383, 23843)\n",
      "Tfidf_Test: (346, 23843)\n"
     ]
    }
   ],
   "source": [
    "# TfidfVectorizer\n",
    "tv = TfidfVectorizer(min_df = 0, max_df = 1, use_idf = True, ngram_range = (1, 3))\n",
    "\n",
    "# Transformed train tweets\n",
    "tv_train_tweets = tv.fit_transform(X_train)\n",
    "\n",
    "# Transformed test tweets\n",
    "tv_test_tweets = tv.transform(X_test)\n",
    "\n",
    "print('Tfidf_Train:',tv_train_tweets.shape)\n",
    "print('Tfidf_Test:',tv_test_tweets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "68d04f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 8671)\t0.30151134457776363\n",
      "  (0, 10739)\t0.30151134457776363\n",
      "  (0, 14388)\t0.30151134457776363\n",
      "  (0, 10741)\t0.30151134457776363\n",
      "  (0, 22607)\t0.30151134457776363\n",
      "  (0, 19926)\t0.30151134457776363\n",
      "  (0, 2474)\t0.30151134457776363\n",
      "  (0, 17411)\t0.30151134457776363\n",
      "  (0, 8670)\t0.30151134457776363\n",
      "  (0, 14387)\t0.30151134457776363\n",
      "  (0, 10740)\t0.30151134457776363\n"
     ]
    }
   ],
   "source": [
    "s = tv_train_tweets[1]\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "cc7f075a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ss = tv_test_tweets[1]\n",
    "print(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "ce8f16b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.1, max_iter=500, random_state=42)\n",
      "LogisticRegression(C=1.1, max_iter=500, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "#logistic regression\n",
    "# Training the Model\n",
    "lr = LogisticRegression(penalty = 'l2', max_iter = 500, C = 1.1, random_state = 42)\n",
    "\n",
    "# Fitting the model for Bag of Words\n",
    "lr_bow = lr.fit(cv_train_tweets, y_train)\n",
    "print(lr_bow)\n",
    "\n",
    "# Fitting the model for TFIDF features\n",
    "lr_tfidf = lr.fit(tv_train_tweets, y_train)\n",
    "print(lr_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "0e1c4d1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Predicting the model for Bag of Words\n",
    "lr_bow_predict = lr.predict(cv_test_tweets)\n",
    "print(lr_bow_predict)\n",
    "\n",
    "# Predicting the model for TFIDF features\n",
    "lr_tfidf_predict = lr.predict(tv_test_tweets)\n",
    "print(lr_tfidf_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "1979a7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR BoW Score : 0.8583815028901735\n",
      "LR TFIDF Score : 0.8526011560693642\n"
     ]
    }
   ],
   "source": [
    "# Accuracy score for Bag of Words\n",
    "lr_bow_score = accuracy_score(y_test, lr_bow_predict)\n",
    "print(\"LR BoW Score :\",lr_bow_score)\n",
    "\n",
    "# Accuracy score for TFIDF features\n",
    "lr_tfidf_score = accuracy_score(y_test, lr_tfidf_predict)\n",
    "print(\"LR TFIDF Score :\",lr_tfidf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "090abe4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.86      1.00      0.92       295\n",
      "     pozitif       1.00      0.04      0.08        51\n",
      "\n",
      "    accuracy                           0.86       346\n",
      "   macro avg       0.93      0.52      0.50       346\n",
      "weighted avg       0.88      0.86      0.80       346\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.85      1.00      0.92       295\n",
      "     pozitif       0.00      0.00      0.00        51\n",
      "\n",
      "    accuracy                           0.85       346\n",
      "   macro avg       0.43      0.50      0.46       346\n",
      "weighted avg       0.73      0.85      0.78       346\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kofana\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Kofana\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Kofana\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Classification report for Bag of Words\n",
    "lr_bow_report = classification_report(y_test, lr_bow_predict, target_names = ['negatif','pozitif'])\n",
    "print(lr_bow_report)\n",
    "\n",
    "# Classification report for TFIDF features\n",
    "lr_tfidf_report = classification_report(y_test, lr_tfidf_predict, target_names = ['negatif','pozitif'])\n",
    "print(lr_tfidf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "fadb070e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2  49]\n",
      " [  0 295]]\n",
      "[[  0  51]\n",
      " [  0 295]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix for Bag of Words\n",
    "cm_bow = confusion_matrix(y_test, lr_bow_predict, labels = [1,0])\n",
    "print(cm_bow)\n",
    "\n",
    "# Confusion matrix for TFIDF features\n",
    "cm_tfidf = confusion_matrix(y_test, lr_tfidf_predict, labels = [1,0])\n",
    "print(cm_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "a28738ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier(max_iter=500, random_state=42)\n",
      "SGDClassifier(max_iter=500, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "# Training the Linear SVM\n",
    "svm = SGDClassifier(loss='hinge', max_iter=500, random_state=42)\n",
    "\n",
    "# Fitting the SVM for Bag of Words\n",
    "svm_bow = svm.fit(cv_train_tweets, y_train)\n",
    "print(svm_bow)\n",
    "\n",
    "# Fitting the SVM for TFIDF features\n",
    "svm_tfidf = svm.fit(tv_train_tweets, y_train)\n",
    "print(svm_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "789e5f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Predicting the model for Bag of Words\n",
    "svm_bow_predict = svm.predict(cv_test_tweets)\n",
    "print(svm_bow_predict)\n",
    "\n",
    "# Predicting the model for TFIDF features\n",
    "svm_tfidf_predict = svm.predict(tv_test_tweets)\n",
    "print(svm_tfidf_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "4b25c6bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM BoW Score : 0.8641618497109826\n",
      "SVM TFIDF Score: 0.861271676300578\n"
     ]
    }
   ],
   "source": [
    "# Accuracy score for Bag of Words\n",
    "svm_bow_score = accuracy_score(y_test, svm_bow_predict)\n",
    "print(\"SVM BoW Score :\",svm_bow_score)\n",
    "\n",
    "# Accuracy score for TFIDF features\n",
    "svm_tfidf_score = accuracy_score(y_test, svm_tfidf_predict)\n",
    "print(\"SVM TFIDF Score:\",svm_tfidf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "9dc23955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.87      0.99      0.93       295\n",
      "     pozitif       0.67      0.16      0.25        51\n",
      "\n",
      "    accuracy                           0.86       346\n",
      "   macro avg       0.77      0.57      0.59       346\n",
      "weighted avg       0.84      0.86      0.83       346\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.86      0.99      0.92       295\n",
      "     pozitif       0.71      0.10      0.17        51\n",
      "\n",
      "    accuracy                           0.86       346\n",
      "   macro avg       0.79      0.55      0.55       346\n",
      "weighted avg       0.84      0.86      0.81       346\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report for Bag of Words \n",
    "svm_bow_report = classification_report(y_test, svm_bow_predict, target_names = ['negatif','pozitif'])\n",
    "print(svm_bow_report)\n",
    "\n",
    "# Classification report for TFIDF features\n",
    "svm_tfidf_report = classification_report(y_test, svm_tfidf_predict, target_names = ['negatif','pozitif'])\n",
    "print(svm_tfidf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "c115c4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  8  43]\n",
      " [  4 291]]\n",
      "[[  5  46]\n",
      " [  2 293]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix for Bag of Words\n",
    "cm_bow = confusion_matrix(y_test, svm_bow_predict, labels = [1,0])\n",
    "print(cm_bow)\n",
    "\n",
    "# Confusion matrix for TFIDF features\n",
    "cm_tfidf = confusion_matrix(y_test, svm_tfidf_predict, labels = [1,0])\n",
    "print(cm_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "01794e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB()\n",
      "MultinomialNB()\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "mnb = MultinomialNB()\n",
    "\n",
    "# Fitting the NB for Bag of Words\n",
    "mnb_bow = mnb.fit(cv_train_tweets, y_train)\n",
    "print(mnb_bow)\n",
    "\n",
    "# Fitting the NB for TFIDF features\n",
    "mnb_tfidf = mnb.fit(tv_train_tweets, y_train)\n",
    "print(mnb_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "4deb2226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Predicting the model for Bag of Words\n",
    "mnb_bow_predict = mnb.predict(cv_test_tweets)\n",
    "print(mnb_bow_predict)\n",
    "\n",
    "# Predicting the model for TFIDF features\n",
    "mnb_tfidf_predict = mnb.predict(tv_test_tweets)\n",
    "print(mnb_tfidf_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "2eecbd79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNB BoW Score : 0.8583815028901735\n",
      "MNB TFIDF Score : 0.8526011560693642\n"
     ]
    }
   ],
   "source": [
    "# Accuracy score for Bag of Words\n",
    "mnb_bow_score = accuracy_score(y_test, mnb_bow_predict)\n",
    "print(\"MNB BoW Score :\",mnb_bow_score)\n",
    "\n",
    "# Accuracy score for TFIDF features\n",
    "mnb_tfidf_score = accuracy_score(y_test, mnb_tfidf_predict)\n",
    "print(\"MNB TFIDF Score :\",mnb_tfidf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "d526af91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.86      1.00      0.92       295\n",
      "     pozitif       1.00      0.04      0.08        51\n",
      "\n",
      "    accuracy                           0.86       346\n",
      "   macro avg       0.93      0.52      0.50       346\n",
      "weighted avg       0.88      0.86      0.80       346\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.85      1.00      0.92       295\n",
      "     pozitif       0.00      0.00      0.00        51\n",
      "\n",
      "    accuracy                           0.85       346\n",
      "   macro avg       0.43      0.50      0.46       346\n",
      "weighted avg       0.73      0.85      0.78       346\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kofana\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Kofana\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Kofana\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Classification report for Bag of Words\n",
    "mnb_bow_report = classification_report(y_test, mnb_bow_predict, target_names = ['negatif','pozitif'])\n",
    "print(mnb_bow_report)\n",
    "\n",
    "# Classification report for TFIDF features\n",
    "mnb_tfidf_report = classification_report(y_test, mnb_tfidf_predict, target_names = ['negatif','pozitif'])\n",
    "print(mnb_tfidf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "b9330e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2  49]\n",
      " [  0 295]]\n",
      "[[  0  51]\n",
      " [  0 295]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix for Bag of Words\n",
    "cm_bow = confusion_matrix(y_test, mnb_bow_predict, labels = [1,0])\n",
    "print(cm_bow)\n",
    "\n",
    "# Confusion matrix for TFIDF features\n",
    "cm_tfidf = confusion_matrix(y_test, mnb_tfidf_predict, labels = [1,0])\n",
    "print(cm_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b66479",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0d9f7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d441563",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0023be7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
